{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58Eyu_mg-irb"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import plotly.express as xp\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq6ETN2oxkKD"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'] = df['TotalCharges'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe(include=[object])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handling Missing Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(columns = ['customerID'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data separation as X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "y\n",
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop('Churn', axis=1)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_test_data_categorical_columns(train_df, test_df):\n",
        "    # Get the list of categorical columns for both train and test DataFrames\n",
        "    train_df_categorical_columns = train_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    test_df_categorical_columns = test_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    # Check if the number of categorical columns is the same in both DataFrames\n",
        "    if len(set(train_df_categorical_columns).intersection(set(test_df_categorical_columns))) == 0:\n",
        "        print('Train and test dataframes have different categorical columns')\n",
        "        return\n",
        "    else:\n",
        "        for cat_col in test_df_categorical_columns:\n",
        "            # Create sets of unique values for the current categorical column in both DataFrames\n",
        "            train_col = set(x for x in train_df[cat_col].unique().tolist() if not pd.isna(x))\n",
        "            test_col = set(x for x in test_df[cat_col].unique().tolist() if not pd.isna(x))\n",
        "\n",
        "            # Check if the sets are not equal, indicating different unique values\n",
        "            if train_col != test_col:\n",
        "                print(f'{cat_col} column has different unique values in train and test data:')\n",
        "                print(f'Unique values in train data: {train_col}')\n",
        "                print(f'Unique values in test data: {test_col}')\n",
        "                return\n",
        "\n",
        "        print('All categorical columns have consistent unique values in train and test data.')\n",
        "        return\n",
        "\n",
        "validate_test_data_categorical_columns(X_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encoding Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "categorical_columns = [\n",
        "    'gender', \n",
        "    'Partner',\n",
        "    'Dependents',\n",
        "    'PhoneService',\n",
        "    'PaperlessBilling' , \n",
        "    'Contract', \n",
        "    'MultipleLines', \n",
        "    'InternetService', \n",
        "    'OnlineSecurity', \n",
        "    'OnlineBackup', \n",
        "    'DeviceProtection', \n",
        "    'TechSupport', \n",
        "    'StreamingTV', \n",
        "    'StreamingMovies',\n",
        "    'PaymentMethod'\n",
        "]\n",
        "\n",
        "label_encoders = {}\n",
        "\n",
        "for column in categorical_columns:\n",
        "    # Fit and transform the column\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column])\n",
        "    # Save the encoder\n",
        "    label_encoders[column] = le\n",
        "\n",
        "print(\"Encoded DataFrame:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Label Encoding Mapping:\")\n",
        "for column, le in label_encoders.items():\n",
        "    print(f\"\\nColumn: {column}\")\n",
        "    for i, label in enumerate(le.classes_):\n",
        "        print(f\"{i}: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in categorical_columns:\n",
        "  le.fit(X_train[column])\n",
        "  X_train[column] = le.transform(X_train[column])\n",
        "\n",
        "for column in categorical_columns:\n",
        "  le.fit(X_test[column])\n",
        "  X_test[column] = le.transform(X_test[column])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_encoders = {\n",
        "    'gender': LabelEncoder().fit(['Female', 'Male']),\n",
        "    'Partner': LabelEncoder().fit(['No', 'Yes']),\n",
        "    'Dependents': LabelEncoder().fit(['No', 'Yes']),\n",
        "    'PhoneService': LabelEncoder().fit(['No', 'Yes']),\n",
        "    'PaperlessBilling': LabelEncoder().fit(['No', 'Yes']),\n",
        "    'Contract': LabelEncoder().fit(['Month-to-month', 'One year', 'Two year']),\n",
        "    'MultipleLines': LabelEncoder().fit(['No', 'No phone service', 'Yes']),\n",
        "    'InternetService': LabelEncoder().fit(['DSL', 'Fiber optic', 'No']),\n",
        "    'OnlineSecurity': LabelEncoder().fit(['No', 'No internet service', 'Yes']),\n",
        "    'OnlineBackup': LabelEncoder().fit(['No', 'No internet service', 'Yes']),\n",
        "    'DeviceProtection': LabelEncoder().fit(['No', 'No internet service', 'Yes']),\n",
        "    'TechSupport': LabelEncoder().fit(['No', 'No internet service', 'Yes']),\n",
        "    'StreamingTV': LabelEncoder().fit(['No', 'No internet service', 'Yes']),\n",
        "    'StreamingMovies': LabelEncoder().fit(['No', 'No internet service', 'Yes']),\n",
        "    'PaymentMethod': LabelEncoder().fit(['Bank transfer (automatic)', 'Credit card (automatic)', 'Electronic check', 'Mailed check'])\n",
        "}\n",
        "\n",
        "# Saving the encoder to a file\n",
        "with open('encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoders, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "rKAUX3DTRcOr",
        "outputId": "350d62da-8e16-4932-b755-e824442d5f8a"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "features = ['MonthlyCharges', 'TotalCharges', 'tenure']\n",
        "df[features] = scaler.fit_transform(df[features])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Summary\n",
        "print(\"---- Data Summary ----\")\n",
        "\n",
        "# Partner and Senior Citizen summary\n",
        "print(\"\\nCount of people with or without partners:\")\n",
        "print(df['Partner'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "print(\"\\nCount of people with or without partners by gender:\")\n",
        "print(df.groupby('gender')['Partner'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "# Dependents summary\n",
        "print(\"\\nCount of people with and without dependents:\")\n",
        "print(df['Dependents'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "print(\"\\nCount of dependents by Senior Citizen status:\")\n",
        "print(df.groupby('SeniorCitizen')['Dependents'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "print(\"\\nCount of dependents by Gender:\")\n",
        "print(df.groupby('gender')['Dependents'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "# Tenure summary\n",
        "print(\"\\nTenure summary:\")\n",
        "print(f\"Minimum Tenure: {df['tenure'].min()} months\")\n",
        "print(f\"Maximum Tenure: {df['tenure'].max()} months\")\n",
        "print(f\"Average Tenure: {df['tenure'].mean():.1f} months\")\n",
        "print(f\"Most Common Tenure: {df['tenure'].mode()[0]} months\")\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "# PhoneService summary\n",
        "print(\"\\nPhoneService subscription counts:\")\n",
        "print(df['PhoneService'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "print(\"\\nPhoneService by Senior Citizen status:\")\n",
        "print(df.groupby('PhoneService')['SeniorCitizen'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "# MultipleLines summary\n",
        "print(\"\\nMultiple Lines subscription counts:\")\n",
        "print(df['MultipleLines'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "# InternetService counts\n",
        "print(\"\\nInternet Service counts:\")\n",
        "print(df['InternetService'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "# Group by gender and InternetService\n",
        "print(\"\\nInternet Service distribution by gender:\")\n",
        "print(df.groupby('gender')['InternetService'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "# Group by Senior Citizen\n",
        "print(\"\\nInternet Service distribution by Senior Citizen status:\")\n",
        "print(df.groupby('SeniorCitizen')['InternetService'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "# Streaming Services summary\n",
        "print(\"\\nStreamingTV distribution by Dependents:\")\n",
        "print(df.groupby('Dependents')['StreamingTV'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "print(\"\\nStreamingMovies distribution:\")\n",
        "print(df['StreamingMovies'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "# Contract summary\n",
        "print(\"\\nContract distribution:\")\n",
        "print(df['Contract'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "# Paperless Billing summary\n",
        "print(\"\\nPaperless Billing distribution:\")\n",
        "print(df['PaperlessBilling'].value_counts())\n",
        "\n",
        "total_paperless = df['PaperlessBilling'].value_counts().sum()\n",
        "paperless_counts = df['PaperlessBilling'].value_counts()\n",
        "paperless_use_percentage = paperless_counts[0] / total_paperless\n",
        "paperless_no_use_percentage = paperless_counts[1] / total_paperless\n",
        "\n",
        "print(f\"{paperless_use_percentage:.2f} % use Paper Billing while {paperless_no_use_percentage:.2f}% do not use Paper Billing\")\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "print(\"\\nPaperless Billing distribution by Gender:\")\n",
        "print(df.groupby('gender')['PaperlessBilling'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "print(\"\\nPaperless Billing distribution by Senior Citizen status:\")\n",
        "print(df.groupby('SeniorCitizen')['PaperlessBilling'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "print(\"\\nPaperless Billing distribution by Dependents:\")\n",
        "print(df.groupby('Dependents')['PaperlessBilling'].value_counts())\n",
        "print('-----------------------------------------------------------')\n",
        "\n",
        "print(\"\\nPaperless Billing distribution by Contract type:\")\n",
        "print(df.groupby('Contract')['PaperlessBilling'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"---- Visualizations ----\")\n",
        "\n",
        "# Gender Distribution\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.countplot(data=df, x='gender')\n",
        "plt.grid()\n",
        "plt.title(\"Gender Distribution\")\n",
        "plt.show()\n",
        "\n",
        "# SeniorCitizen vs Gender\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.countplot(data=df, x='SeniorCitizen', hue='gender')\n",
        "plt.grid()\n",
        "plt.title(\"SeniorCitizen VS Gender\")\n",
        "plt.show()\n",
        "\n",
        "# Partner vs SeniorCitizen and Partner vs Gender\n",
        "plt.figure(figsize=(11, 6))\n",
        "\n",
        "# Subplot 1: Partner vs Senior Citizen\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(data=df, x='Partner', hue='SeniorCitizen')\n",
        "plt.grid()\n",
        "plt.title(\"Partner VS Senior Citizen\")\n",
        "\n",
        "# Subplot 2: Partner vs Gender\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(data=df, x='Partner', hue='gender')\n",
        "plt.grid()\n",
        "plt.title(\"Partner VS Gender\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Dependents vs SeniorCitizen and Dependents vs Gender\n",
        "plt.figure(figsize=(11, 6))\n",
        "\n",
        "# Subplot 1: Dependents vs Senior Citizen\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(data=df, x='Dependents', hue='SeniorCitizen')\n",
        "plt.grid()\n",
        "plt.title(\"Dependents VS Senior Citizen\")\n",
        "\n",
        "# Subplot 2: Dependents vs Gender\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(data=df, x='Dependents', hue='gender')\n",
        "plt.grid()\n",
        "plt.title(\"Dependents VS Gender\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Tenure Distribution by Gender\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(data=df, x='tenure', hue='gender', kde=True, multiple=\"stack\")\n",
        "plt.title(\"Tenure Distribution by Gender\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# PhoneService related plots\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# Subplot 1: PhoneService vs Dependents\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.countplot(data=df, x='PhoneService', hue='Dependents')\n",
        "plt.grid()\n",
        "plt.title(\"PhoneService VS Dependents\")\n",
        "\n",
        "# Subplot 2: PhoneService vs Senior Citizen\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.countplot(data=df, x='PhoneService', hue='SeniorCitizen')\n",
        "plt.grid()\n",
        "plt.title(\"PhoneService VS Senior Citizen\")\n",
        "\n",
        "# Subplot 3: PhoneService vs Gender\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.countplot(data=df, x='PhoneService', hue='gender')\n",
        "plt.grid()\n",
        "plt.title(\"PhoneService VS Gender\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# InternetService related plots\n",
        "plt.figure(figsize=(16, 4))\n",
        "\n",
        "# Subplot 1: InternetService vs PhoneService\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.countplot(data=df, x='InternetService', hue='PhoneService')\n",
        "plt.grid()\n",
        "plt.title(\"InternetService VS PhoneService\")\n",
        "\n",
        "# Subplot 2: InternetService vs SeniorCitizen\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.countplot(data=df, x='InternetService', hue='SeniorCitizen')\n",
        "plt.grid()\n",
        "plt.title(\"InternetService VS SeniorCitizen\")\n",
        "\n",
        "# Subplot 3: InternetService vs Gender\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.countplot(data=df, x='InternetService', hue='gender')\n",
        "plt.grid()\n",
        "plt.title(\"InternetService VS Gender\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# StreamingMovies related plots\n",
        "plt.figure(figsize=(16, 4))\n",
        "\n",
        "# Subplot 1: StreamingMovies vs Dependents\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.countplot(data=df, hue='StreamingMovies', x='Dependents')\n",
        "plt.grid()\n",
        "plt.title(\"StreamingMovies VS Dependents\")\n",
        "\n",
        "# Subplot 2: StreamingMovies vs SeniorCitizen\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.countplot(data=df, hue='StreamingMovies', x='SeniorCitizen')\n",
        "plt.grid()\n",
        "plt.title(\"StreamingMovies VS SeniorCitizen\")\n",
        "\n",
        "# Subplot 3: StreamingMovies vs Gender\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.countplot(data=df, hue='StreamingMovies', x='gender')\n",
        "plt.grid()\n",
        "plt.title(\"StreamingMovies VS Gender\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Contract related plots\n",
        "plt.figure(figsize=(16, 4))\n",
        "\n",
        "# Subplot 1: Contract vs Dependents\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.countplot(data=df, hue='Contract', x='Dependents')\n",
        "plt.grid()\n",
        "plt.title(\"Contract VS Dependents\")\n",
        "\n",
        "# Subplot 2: Contract vs SeniorCitizen\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.countplot(data=df, hue='Contract', x='SeniorCitizen')\n",
        "plt.grid()\n",
        "plt.title(\"Contract VS SeniorCitizen\")\n",
        "\n",
        "# Subplot 3: Contract vs Gender\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.countplot(data=df, hue='Contract', x='gender')\n",
        "plt.grid()\n",
        "plt.title(\"Contract VS Gender\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# PaperlessBilling related plots\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: PaperlessBilling vs Dependents\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(data=df, hue='PaperlessBilling', x='Dependents')\n",
        "plt.grid()\n",
        "plt.title(\"PaperlessBilling VS Dependents\")\n",
        "\n",
        "# Subplot 2: PaperlessBilling vs SeniorCitizen\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(data=df, hue='PaperlessBilling', x='SeniorCitizen')\n",
        "plt.grid()\n",
        "plt.title(\"PaperlessBilling VS SeniorCitizen\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# PaperlessBilling vs Gender and Contract\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: PaperlessBilling vs Gender\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(data=df, hue='PaperlessBilling', x='gender')\n",
        "plt.grid()\n",
        "plt.title(\"PaperlessBilling VS Gender\")\n",
        "\n",
        "# Subplot 2: PaperlessBilling vs Contract\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(data=df, hue='PaperlessBilling', x='Contract')\n",
        "plt.grid()\n",
        "plt.title(\"PaperlessBilling VS Contract\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Independent Features Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select numerical features and drop the 'Churn' column\n",
        "independent_features_df = df.select_dtypes(include=['number'])\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr_matrix = independent_features_df.corr()\n",
        "\n",
        "# Create a mask to hide the upper triangle of the heatmap\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "\n",
        "# Set the figure size and font scale for better readability\n",
        "plt.figure(figsize=(18, 8))\n",
        "sns.set(font_scale=1.2)\n",
        "\n",
        "# Create the heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", mask=mask, vmin=-1, vmax=1)\n",
        "\n",
        "# Set the title and show the plot\n",
        "plt.title(\"Independent Features Correlation Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inpedendent features correlation with prediction labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Compute the correlation matrix\n",
        "correlation_data = df.select_dtypes(include=['number']).corr()['Churn']\n",
        "\n",
        "# Convert Series to DataFrame for heatmap\n",
        "correlation_data = correlation_data.to_frame()\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(correlation_data, annot=True, cmap=\"coolwarm\", cbar=True, vmin=-1, vmax=1)\n",
        "# sns.heatmap(churn_correlation.to_frame(), annot=True, cmap=\"coolwarm\", cbar=True)\n",
        "\n",
        "plt.title(\"Correlation Heatmap between Independent Features and Churn\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdEUv9Hm0hTK"
      },
      "source": [
        "# **Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_evaluation_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    results = [accuracy, precision, recall, f1]\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print()\n",
        "    \n",
        "    class_report = classification_report(y_true, y_pred)\n",
        "    print(\"Classification Report:\")\n",
        "    print(class_report)\n",
        "    \n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    cm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0, 1])\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "    cm_display.plot()\n",
        "    plt.show()\n",
        "    print()\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def k_fold_cross_validation_with_metrics(classifier, X, y, k_folds=5):\n",
        "    \n",
        "    # Initializing stratified k-fold cross-validation\n",
        "    stratified_kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # Lists to store the evaluation metrics for each fold\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "\n",
        "    # Perform cross-validation\n",
        "    for train_index, test_index in stratified_kf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Fit the classifier on the training data\n",
        "        classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on the test data\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        # Calculate evaluation metrics for this fold\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "\n",
        "        # Append the metrics to their respective lists\n",
        "        accuracy_scores.append(accuracy)\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "\n",
        "    # Calculate and print the mean of each metric across all folds\n",
        "    mean_accuracy = np.mean(accuracy_scores)\n",
        "    mean_precision = np.mean(precision_scores)\n",
        "    mean_recall = np.mean(recall_scores)\n",
        "    print(\"Mean Metrics Across Folds:\")\n",
        "    print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
        "    print(f\"Mean Precision: {mean_precision:.2f}\")\n",
        "    print(f\"Mean Recall: {mean_recall:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuYBNNel2cB6"
      },
      "source": [
        "## **K Nearest Neighbour (KNN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6GKNSWg2cB7"
      },
      "source": [
        "### **Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAoTBVbV2cB7",
        "outputId": "64b3ff7b-0e18-407e-9168-d176169b608a"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE55dFds2cB8"
      },
      "source": [
        "### **Applying the Model to make a Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "J8mJ0nNi2cB8"
      },
      "outputs": [],
      "source": [
        "y_knn_pred = knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4keI5PK2cB9",
        "outputId": "6f3c20eb-6487-463c-88e1-d4255bb81037"
      },
      "outputs": [],
      "source": [
        "y_knn_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGZ3qQqb2cB-"
      },
      "source": [
        "### **Evaluate Model Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGA2KJm-2cB-",
        "outputId": "f948787f-31b4-4407-a1f0-09a61e062cd7"
      },
      "outputs": [],
      "source": [
        "knn_metrics = print_evaluation_metrics(y_test, y_knn_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zEK9br6e2cB_"
      },
      "outputs": [],
      "source": [
        "knn_results = pd.DataFrame(['K Nearest Neighbour', knn_metrics[0], knn_metrics[1], knn_metrics[2], knn_metrics[3]]).transpose()\n",
        "knn_results.columns = ['Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDoGk2wv2cB_",
        "outputId": "800c5afd-9d07-4344-81ca-dd5b08e1886b"
      },
      "outputs": [],
      "source": [
        "knn_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s4DcSV3XkrH"
      },
      "source": [
        "## **Support Vector Machines (SVM)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS1xER7YXkrY"
      },
      "source": [
        "### **Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO5nf-n1XkrY",
        "outputId": "0bf404fb-5f61-48c8-a486-0434b8e57758"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbfEEuLbXkrZ"
      },
      "source": [
        "### **Applying the Model to make a Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ns1XuIZ_XkrZ"
      },
      "outputs": [],
      "source": [
        "y_svm_pred = svm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig0soxLAXkrZ",
        "outputId": "316c8b79-0b54-41a8-9ab5-4daa0b2f549b"
      },
      "outputs": [],
      "source": [
        "y_svm_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bvAl5zZXkra"
      },
      "source": [
        "### **Evaluate Model Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUqZEykyXkra",
        "outputId": "ca240ce0-7a7d-4816-f726-c12294fe23ca"
      },
      "outputs": [],
      "source": [
        "svm_metrics = print_evaluation_metrics(y_test, y_svm_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iyI5nq0xXkra"
      },
      "outputs": [],
      "source": [
        "svm_results = pd.DataFrame(['Support Vector Machines', svm_metrics[0], svm_metrics[1], svm_metrics[2], svm_metrics[3]]).transpose()\n",
        "svm_results.columns = ['Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AalCsPHPXkra",
        "outputId": "6528f701-3592-4968-8032-bc0398f3bc26"
      },
      "outputs": [],
      "source": [
        "svm_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrM0J3bqIeHW"
      },
      "source": [
        "## **Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8U-syo_IeHp"
      },
      "source": [
        "### **Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJR_3UrBIeHp",
        "outputId": "80804675-1223-4a6c-8952-1e327fedd68f"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression(max_iter=1000) #the max iter need to be removed after done the data prep processing\n",
        "lr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhYrfeyHIeHq"
      },
      "source": [
        "### **Applying the Model to make a Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VXxMS_yHIeHr"
      },
      "outputs": [],
      "source": [
        "y_lr_pred = lr.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8azwcwENIeHr",
        "outputId": "993b4086-6bea-430f-cdcf-8a4c53e4f144"
      },
      "outputs": [],
      "source": [
        "y_lr_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIjL0mzEIeHr"
      },
      "source": [
        "### **Evaluate Model Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RuNxNATIeHs",
        "outputId": "eb108f06-3b21-4059-a384-c2950a769d4c"
      },
      "outputs": [],
      "source": [
        "lr_metrics = print_evaluation_metrics(y_test, y_lr_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "nKz0wXjrIeHs"
      },
      "outputs": [],
      "source": [
        "lr_results = pd.DataFrame(['Logistic Regression', lr_metrics[0], lr_metrics[1], lr_metrics[2], lr_metrics[3]]).transpose()\n",
        "lr_results.columns = ['Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXHksHuMIeHs",
        "outputId": "2ce69bf7-984c-4e33-a802-b9205c81ead0"
      },
      "outputs": [],
      "source": [
        "lr_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Decision Tree**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Applying the Model to make a Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_dt_pred = dt.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_dt_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Evaluate Model Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_metrics = print_evaluation_metrics(y_test, y_dt_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_results = pd.DataFrame(['Decision Tree', dt_metrics[0], dt_metrics[1], dt_metrics[2], dt_metrics[3]]).transpose()\n",
        "dt_results.columns = ['Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzBkczuwOXlh"
      },
      "source": [
        "### **Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ8r-pyZOXli",
        "outputId": "2054aeed-a1d7-4233-aaab-79111dc6a978"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "farDhca9OXli"
      },
      "source": [
        "### **Applying the Model to make a Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "bgGEFU-dOXli"
      },
      "outputs": [],
      "source": [
        "y_rf_pred = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzEGoR_AOXli",
        "outputId": "319bd0b0-7fdb-404e-daf6-08f7bd350831"
      },
      "outputs": [],
      "source": [
        "y_rf_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3h3isjkOXli"
      },
      "source": [
        "### **Evaluate Model Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqvXNBzMOXlj",
        "outputId": "b1df4a15-3914-4ad8-dad8-7c861c83d036"
      },
      "outputs": [],
      "source": [
        "rf_metrics = print_evaluation_metrics(y_test, y_rf_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "CjfwLVcDOXlj"
      },
      "outputs": [],
      "source": [
        "rf_results = pd.DataFrame(['Random Forest', rf_metrics[0], rf_metrics[1], rf_metrics[2], rf_metrics[3]]).transpose()\n",
        "rf_results.columns = ['Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1YkzVWIOXlj",
        "outputId": "69bef663-29f9-4609-aab5-e0047f348b2b"
      },
      "outputs": [],
      "source": [
        "rf_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYqR9hGCVKOc"
      },
      "source": [
        "# **Model Comparison**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Cross Validation Mean Metrics\")\n",
        "print(\"\\nK Nearest Neighbour CV Mean Metrics: \")\n",
        "k_fold_cross_validation_with_metrics(knn, X_train, y_train)\n",
        "print(\"\\nSupport Vector Machine CV Mean Metrics: \")\n",
        "k_fold_cross_validation_with_metrics(svm, X_train, y_train)\n",
        "print(\"\\nLogistic Regression CV Mean Metrics: \")\n",
        "k_fold_cross_validation_with_metrics(lr, X_train, y_train)\n",
        "print(\"\\nDecision Tree CV Mean Metrics: \")\n",
        "k_fold_cross_validation_with_metrics(dt, X_train, y_train)\n",
        "print(\"\\nRandom Forest CV Mean Metrics: \")\n",
        "k_fold_cross_validation_with_metrics(rf, X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "PJBoe3xcZriQ",
        "outputId": "8a0e9498-72e4-4d6b-fc02-6e1c6b58448e"
      },
      "outputs": [],
      "source": [
        "df_models = pd.concat([knn_results, svm_results, lr_results, dt_results, rf_results], axis=0)\n",
        "df_models.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\"K Nearest Neighbour\": (knn, knn_metrics[0]), \n",
        "\"Support Vector Machines\": (svm, svm_metrics[0]), \n",
        "\"Logistic Regression\": (lr, lr_metrics[0]), \n",
        "\"Decision Tree\": (dt, dt_metrics[0]), \n",
        "\"Random Forest\": (rf, rf_metrics[0])}\n",
        "\n",
        "Best_acc = 0.0\n",
        "Best_model = None\n",
        "\n",
        "for name, (model, acc) in models.items():\n",
        "    acc = acc*100\n",
        "    print(f\"Accuracy score of {name} is {acc:.2f}%\\n\")\n",
        "    \n",
        "    if acc>Best_acc:\n",
        "        Best_acc = acc\n",
        "        Best_model = name\n",
        "        chosen_model = model\n",
        "        \n",
        "# Printing the best parameters and score\n",
        "print(f\"Best Model is {Best_model} with {Best_acc:.2f}% accuracy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"customer_churn_model.pkl\", 'wb') as model_file:\n",
        "    pickle.dump(chosen_model, model_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Deployment of Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomerChurnClassifier:\n",
        "    \n",
        "    def __init__(self, model_path, encoder_path):\n",
        "        # Load the model\n",
        "        with open(model_path, 'rb') as file:\n",
        "            self.model = pickle.load(file)\n",
        "        \n",
        "        # Load the LabelEncoders\n",
        "        with open(encoder_path, 'rb') as file:\n",
        "            self.encoders = pickle.load(file)\n",
        "    \n",
        "    def predict(self, tenure: int, phone_service: str, multiple_lines: str, internet_service: str, online_security: str, online_backup: str, device_protection: str, tech_support: str, streaming_tv: str, streaming_movies: str, contract: str, paperless_billing: str, payment_method: str, monthly_charges: float, total_charges: float, gender: str, senior_citizen: int, partner: str, dependents: str):\n",
        "        \n",
        "        # Checking input datatypes\n",
        "        expected_data_types = [int, str, str, str, str, str, str, str, str, str, str, str, str, float, float, str, int, str, str]\n",
        "        input_arguments = [tenure, phone_service, multiple_lines, internet_service, online_security, online_backup, device_protection, tech_support, streaming_tv, streaming_movies, contract, paperless_billing, payment_method, monthly_charges, total_charges, gender, senior_citizen, partner, dependents]\n",
        "        input_arguments_names = ['tenure', 'phone_service', 'multiple_lines', 'internet_service', 'online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies', 'contract', 'paperless_billing', 'payment_method', 'monthly_charges', 'total_charges', 'gender', 'senior_citizen', 'partner', 'dependents']\n",
        "\n",
        "        for i in range(len(input_arguments)):\n",
        "            current_arg_type = type(input_arguments[i])\n",
        "            if current_arg_type != expected_data_types[i]:\n",
        "                raise TypeError(f\"Error: Given {input_arguments_names[i]} ({current_arg_type.__name__}) is not of the expected type ({expected_data_types[i].__name__}).\")\n",
        "        \n",
        "        # Transform categorical features using LabelEncoder\n",
        "        encoded_features = [\n",
        "            self.encoders['gender'].transform([gender])[0],\n",
        "            self.encoders['Partner'].transform([partner])[0],\n",
        "            self.encoders['Dependents'].transform([dependents])[0],\n",
        "            self.encoders['PhoneService'].transform([phone_service])[0],\n",
        "            self.encoders['MultipleLines'].transform([multiple_lines])[0],\n",
        "            self.encoders['InternetService'].transform([internet_service])[0],\n",
        "            self.encoders['OnlineSecurity'].transform([online_security])[0],\n",
        "            self.encoders['OnlineBackup'].transform([online_backup])[0],\n",
        "            self.encoders['DeviceProtection'].transform([device_protection])[0],\n",
        "            self.encoders['TechSupport'].transform([tech_support])[0],\n",
        "            self.encoders['StreamingTV'].transform([streaming_tv])[0],\n",
        "            self.encoders['StreamingMovies'].transform([streaming_movies])[0],\n",
        "            self.encoders['Contract'].transform([contract])[0],\n",
        "            self.encoders['PaperlessBilling'].transform([paperless_billing])[0],\n",
        "            self.encoders['PaymentMethod'].transform([payment_method])[0]\n",
        "        ]\n",
        "        \n",
        "        # Combine numerical and encoded features\n",
        "        to_predict_array = [senior_citizen, tenure, monthly_charges, total_charges] + encoded_features\n",
        "        to_predict_array = np.array(to_predict_array).reshape((1, -1))\n",
        "        \n",
        "        # Make prediction\n",
        "        prediction = self.model.predict(to_predict_array)[0]\n",
        "\n",
        "        if prediction > 0.5:\n",
        "            return 'Will Churn'\n",
        "        else:\n",
        "            return \"Won't Churn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "customer_churn = CustomerChurnClassifier(\n",
        "    model_path = 'customer_churn_model.pkl', \n",
        "    encoder_path = 'encoder.pkl'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Won't Churn\""
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "customer_churn.predict(\n",
        "    tenure=18,\n",
        "    phone_service='No',\n",
        "    multiple_lines='No phone service',\n",
        "    internet_service='DSL',\n",
        "    online_security='No',\n",
        "    online_backup='No',\n",
        "    device_protection='Yes',\n",
        "    tech_support='No',\n",
        "    streaming_tv='Yes',\n",
        "    streaming_movies='No',\n",
        "    contract='Month-to-month',\n",
        "    paperless_billing='No',\n",
        "    payment_method='Electronic check',\n",
        "    monthly_charges=70.50,\n",
        "    total_charges=1250.00,\n",
        "    gender='Female',\n",
        "    senior_citizen=0,\n",
        "    partner='No',\n",
        "    dependents='Yes'\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
